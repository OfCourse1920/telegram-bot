import os
import time
import asyncio
import logging
import re
from collections import defaultdict
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from telegram.constants import ParseMode
import google.generativeai as genai

# --- Configuration ---

# Configure logging to see events and errors
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO)
logger = logging.getLogger(__name__)

# Get tokens from environment variables
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

# --- Gemini AI Configuration ---

# Configure the Gemini API client
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash")

# --- Bot State and History Management ---

# Store conversation histories for each user. The key is the user_id.
# The value is a list of dictionaries in the format Gemini expects.
user_conversations = defaultdict(list)
# Store the timestamp of the last message from each user for rate limiting
user_last_message = defaultdict(float)

# Constants
RATE_LIMIT = 2  # Seconds to wait between messages from a user
MAX_HISTORY_LENGTH = 10  # Max number of messages (5 user, 5 model) to keep in history

# This is the crucial instruction that tells the AI how to behave.
# It's included at the start of every new conversation.
SYSTEM_PROMPT = {
    "role":
    "user",
    "parts": [
        "You are a helpful and friendly Telegram assistant named 'Durginand AI'. "
        "Your goal is to provide accurate and concise answers. "
        "Please format your responses using Telegram's MarkdownV2 style. "
        "This means you should: "
        "- Use *bold text* for emphasis. "
        "- Use _italic text_ for less emphasis. "
        "- Use `inline code` for short code snippets or technical terms. "
        "- Use ```language\ncode block\n``` for longer code examples. "
        "- You MUST escape the following characters with a leading backslash: . - ! "
        "Do not start your response with 'Assistant:' or any other prefix. Just provide the answer directly."
    ]
}
# The initial response from the model after receiving the system prompt.
INITIAL_MODEL_RESPONSE = {
    "role": "model",
    "parts": ["Hello! I'm ready to help. How can I assist you today?"]
}


def escape_markdown_v2(text: str) -> str:
    """A simple function to escape characters for Telegram's MarkdownV2."""
    # This is used for text we control, like user names, to prevent formatting issues.
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    return re.sub(f'([{re.escape(escape_chars)}])', r'\\\1', text)


def get_user_history(user_id: int) -> list:
    """
    Retrieves the conversation history for a user.
    If no history exists, it initializes it with the system prompt.
    """
    if not user_conversations[user_id]:
        # Start a new conversation
        user_conversations[user_id] = [SYSTEM_PROMPT, INITIAL_MODEL_RESPONSE]
    return user_conversations[user_id]


def clear_history(user_id: int):
    """Clears a user's conversation history."""
    if user_id in user_conversations:
        del user_conversations[user_id]


# --- Command Handlers ---


async def start_command(update: Update,
                        context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handles the /start command. Clears history and sends a welcome message."""
    user = update.effective_user
    clear_history(user.id)
    # Prime the history for the new conversation
    initial_response = get_user_history(user.id)[1]['parts'][0]

    welcome_message = f"""
ü§ñ *Hello {escape_markdown_v2(user.first_name)}!*

I'm an AI\\-powered Telegram bot using Google's Gemini AI\\. I can remember our recent conversation for context\\.

*Commands:*
‚Ä¢ `/new` \\- Start a fresh conversation
‚Ä¢ `/help` \\- Show help information
‚Ä¢ `/history` \\- View our recent chat

{escape_markdown_v2(initial_response)}
"""
    await update.message.reply_text(welcome_message,
                                    parse_mode=ParseMode.MARKDOWN_V2)


async def help_command(update: Update,
                       context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handles the /help command."""
    help_text = """
üìã *How to use this bot*

1\\. Just send me a message and I'll reply\\.
2\\. I remember the last few messages of our conversation for context\\.
3\\. Your responses and mine support _MarkdownV2_ formatting\\.

*Commands:*
‚Ä¢ `/start` or `/new` \\- Start a new conversation
‚Ä¢ `/help` \\- Show this help message
‚Ä¢ `/history` \\- View your recent chat history
"""
    await update.message.reply_text(help_text,
                                    parse_mode=ParseMode.MARKDOWN_V2)


async def new_conversation_command(update: Update,
                                   context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handles /new and /reset commands. Clears the conversation history."""
    clear_history(update.effective_user.id)
    # Prime the history again
    get_user_history(update.effective_user.id)
    await update.message.reply_text(
        "üîÑ *New conversation started!* What's on your mind?",
        parse_mode=ParseMode.MARKDOWN_V2)


async def history_command(update: Update,
                          context: ContextTypes.DEFAULT_TYPE) -> None:
    """Displays the user's recent conversation history."""
    user_id = update.effective_user.id
    history = get_user_history(user_id)

    if len(history) <= 2:  # Only system prompt and initial reply exist
        await update.message.reply_text(
            "üì≠ No conversation history to show yet\\.",
            parse_mode=ParseMode.MARKDOWN_V2)
        return

    # Format history for display, skipping the initial system prompt
    history_text = "üìö *Your Recent Conversation:*\n\n"
    for message in history[1:]:
        role = "You" if message['role'] == 'user' else "AI"
        # Escape user-provided text to prevent markdown injection
        text = escape_markdown_v2(message['parts'][0])
        history_text += f"*{role}:* {text}\n"

    try:
        await update.message.reply_text(history_text,
                                        parse_mode=ParseMode.MARKDOWN_V2)
    except Exception as e:
        logger.error(f"Error sending history: {e}")
        # Fallback to plain text if Markdown fails for any reason
        plain_history = "\n".join([
            f"{'You' if m['role'] == 'user' else 'AI'}: {m['parts'][0]}"
            for m in history[1:]
        ])
        await update.message.reply_text(
            f"*Conversation History:*\n\n{plain_history}")


# --- Core AI and Message Handling Logic ---


async def generate_ai_response(user_id: int, text: str) -> str:
    """
    Generates a response from Gemini, handles the API call, and updates the conversation history.
    """
    try:
        # Get the user's current conversation history.
        history = get_user_history(user_id)

        # Start a chat session with the existing history. This provides context.
        chat = model.start_chat(history=history)

        # Send the new user message to the model.
        response = await chat.send_message_async(text)
        ai_reply = response.text

        # Update our master conversation history with the latest state from the chat session.
        # This now includes both the user's latest message and the AI's response.
        user_conversations[user_id] = chat.history

        # Trim the history to prevent it from growing too large.
        while len(user_conversations[user_id]) > MAX_HISTORY_LENGTH + 2:
            # Remove the oldest user/model pair (after the initial system prompts).
            del user_conversations[user_id][2:4]

        return ai_reply

    except Exception as e:
        logger.error(f"AI generation error: {e}")
        if "rate limit" in str(e).lower():
            return "üïí *Rate limit reached\\.* Please wait a moment and try again\\."
        # Provide a more user-friendly error for other API issues
        return "üî¥ An error occurred while processing your request\\. Please try again later\\."


async def handle_message(update: Update,
                         context: ContextTypes.DEFAULT_TYPE) -> None:
    """The main message handler. Processes user messages and gets AI responses."""
    user_id = update.effective_user.id
    text = update.message.text

    # --- Rate Limiting ---
    current_time = time.time()
    if current_time - user_last_message[user_id] < RATE_LIMIT:
        logger.info(f"Rate limit hit for user {user_id}. Ignoring message.")
        return
    user_last_message[user_id] = current_time

    # Show "typing..." action to the user
    await context.bot.send_chat_action(chat_id=update.effective_chat.id,
                                       action="typing")

    # Generate AI response. This function now also handles all history updates.
    ai_reply = await generate_ai_response(user_id, text)

    try:
        # The AI is expected to return MarkdownV2-compatible text based on the system prompt
        await update.message.reply_text(ai_reply,
                                        parse_mode=ParseMode.MARKDOWN_V2)
    except Exception as e:
        logger.error(
            f"Telegram API Error sending message: {e}. Falling back to plain text."
        )
        # If Markdown parsing fails, send as plain text as a fallback
        await update.message.reply_text(ai_reply)


async def error_handler(update: object,
                        context: ContextTypes.DEFAULT_TYPE) -> None:
    """Logs errors and sends a generic error message to the user."""
    logger.error(f"Exception while handling an update: {context.error}")
    if isinstance(update, Update) and update.effective_message:
        try:
            await update.effective_message.reply_text(
                "‚ö†Ô∏è Apologies, something went wrong\\. Please try again\\.")
        except Exception as e:
            logger.error(f"Failed to send error message to user: {e}")


# --- Bot Entry Point ---


def main() -> None:
    """Starts the bot."""
    if not TELEGRAM_TOKEN or not GEMINI_API_KEY:
        logger.critical(
            "FATAL: Please set TELEGRAM_TOKEN and GEMINI_API_KEY environment variables."
        )
        return

    logger.info("üöÄ Starting Telegram Gemini AI bot...")
    app = Application.builder().token(TELEGRAM_TOKEN).build()

    # Register command handlers
    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("new", new_conversation_command))
    app.add_handler(CommandHandler("reset",
                                   new_conversation_command))  # Alias for /new
    app.add_handler(CommandHandler("history", history_command))

    # Register the message handler for all non-command text messages
    app.add_handler(
        MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Register the error handler
    app.add_error_handler(error_handler)

    # Start polling for updates
    logger.info("Bot started and is now polling.")
    app.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()
